{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b360123-0aa0-41d8-a957-b6907538abe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np, matplotlib.pyplot as plt\n",
    "import mlflow\n",
    "from tqdm import tqdm \n",
    "from transformers import BertTokenizer, BertModel, BertForMaskedLM, BertForPreTraining\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44cbe23c-9698-4da7-91d4-95ebcc97d816",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Instantiate tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7d586c-253f-4c08-9401-94f0e4ba5a6e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0102, -0.0615, -0.0265,  ..., -0.0199, -0.0372, -0.0098],\n",
      "        [-0.0117, -0.0600, -0.0323,  ..., -0.0168, -0.0401, -0.0107],\n",
      "        [-0.0198, -0.0627, -0.0326,  ..., -0.0165, -0.0420, -0.0032],\n",
      "        ...,\n",
      "        [-0.0218, -0.0556, -0.0135,  ..., -0.0043, -0.0151, -0.0249],\n",
      "        [-0.0462, -0.0565, -0.0019,  ...,  0.0157, -0.0139, -0.0095],\n",
      "        [ 0.0015, -0.0821, -0.0160,  ..., -0.0081, -0.0475,  0.0753]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Check default parameters\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b6ca9fa-ef1b-49e7-8cea-c994c25daa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pd.read_csv('../data/all_feedback_consolidated.csv')['Text_Eng'].drop_duplicates().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6751a368-e953-40f5-a3f6-73b16971198c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9920"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f218ba82-034c-4900-b4e8-903f7d62702f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text\n",
    "inputs = tokenizer(text, return_tensors='pt', max_length=512, truncation=True, padding='max_length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d43c8c4c-bd73-4eae-b082-aa4efecff6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels will be same as input, with random words being masked\n",
    "inputs['labels'] = inputs.input_ids.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c997b95-714e-4aff-b41b-6b66f788f510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random array of floats with equal dimensions to input_ids tensor\n",
    "rand = torch.rand(inputs.input_ids.shape)\n",
    "# create mask array\n",
    "mask_arr = (rand < 0.15) * (inputs.input_ids != 101) * \\\n",
    "           (inputs.input_ids != 102) * (inputs.input_ids != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69bc794-4e27-4dd9-8cbf-a42661db903c",
   "metadata": {},
   "outputs": [],
   "source": [
    "selection = []\n",
    "\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    selection.append(\n",
    "        torch.flatten(mask_arr[i].nonzero()).tolist()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "014ccb75-00f8-4c95-9000-f89d19a9706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert selected words to masked (token 103)\n",
    "for i in range(inputs.input_ids.shape[0]):\n",
    "    inputs.input_ids[i, selection[i]] = 103"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "014fcb6e-12c6-40cf-bebf-e6489cff729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings):\n",
    "        self.encodings = encodings\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "24529a7c-b397-488a-a1aa-6a7f28fff053",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fd20524f-503f-4cd6-8064-35922d8d5013",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch.utils.data.DataLoader(dataset, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c791ffa8-20b9-40ff-8c19-2b1178f8bb7c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# activate training mode\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5985cb8-ecda-417b-9f98-5dc8844dc5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "# initialize optimizer\n",
    "optim = Adam(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e94f411-036c-4ed8-9207-1a662cfa6a4d",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1240 [00:00<?, ?it/s]<ipython-input-12-d87c8321e905>:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "Train Epoch 1: 100%|███████████████████████████████████████████████| 1240/1240 [6:01:10<00:00, 17.48s/it, loss=0.00648]\n",
      "Train Epoch 2: 100%|███████████████████████████████████████████████| 1240/1240 [6:21:33<00:00, 18.46s/it, loss=0.00609]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm  # for our progress bar\n",
    "batch_losses = []\n",
    "epochs = 2\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # setup loop with TQDM and dataloader\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for batch in loop:\n",
    "        # initialize calculated gradients (from prev step)\n",
    "        optim.zero_grad()\n",
    "        # pull all tensor batches required for training\n",
    "        input_ids = batch['input_ids']#.to(device)\n",
    "        attention_mask = batch['attention_mask']#.to(device)\n",
    "        labels = batch['labels']#.to(device)\n",
    "        # process\n",
    "        outputs = model(input_ids, attention_mask=attention_mask,\n",
    "                        labels=labels)\n",
    "        \n",
    "        # extract loss\n",
    "        loss = outputs.loss\n",
    "        # calculate loss for every parameter that needs grad update\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optim.step()\n",
    "        # print relevant info to progress bar\n",
    "        loop.set_description(f'Train Epoch {epoch+1}')\n",
    "        loop.set_postfix(loss=loss.item())\n",
    "        batch_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fb0f9809-4db7-42e9-89a8-9beca7ccd2c4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0059, -0.0647, -0.0223,  ..., -0.0194, -0.0395, -0.0052],\n",
      "        [-0.0161, -0.0565, -0.0363,  ..., -0.0175, -0.0377, -0.0146],\n",
      "        [-0.0242, -0.0591, -0.0367,  ..., -0.0171, -0.0395, -0.0073],\n",
      "        ...,\n",
      "        [-0.0255, -0.0521, -0.0174,  ..., -0.0049, -0.0126, -0.0297],\n",
      "        [-0.0502, -0.0526, -0.0060,  ...,  0.0151, -0.0111, -0.0148],\n",
      "        [-0.0030, -0.0788, -0.0211,  ..., -0.0080, -0.0457,  0.0677]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Check that model weights have been updated\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c0598f3-089f-4490-9d9d-95aff6a43a8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(batch_losses, label='training loss')\n",
    "plt.title('Loss at the end of each epoch')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40dad3e7-b568-4387-aeaa-387133070650",
   "metadata": {},
   "source": [
    "# Save tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "282327a2-5258-4f48-81a4-3aaf36f56e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/finetuned_bert/tokenizer_config.json',\n",
       " '../models/finetuned_bert/special_tokens_map.json',\n",
       " '../models/finetuned_bert/vocab.txt',\n",
       " '../models/finetuned_bert/added_tokens.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"../models/finetuned_bert/\")\n",
    "tokenizer.save_pretrained(\"../models/finetuned_bert/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997f22ef-046f-42b6-90cf-9d7f6617e652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
